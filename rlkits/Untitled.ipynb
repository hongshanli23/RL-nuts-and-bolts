{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "expensive-symposium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from env_batch import ParallelEnvBatch\n",
    "\n",
    "\n",
    "def make_env():\n",
    "    return gym.make('Pendulum-v0')\n",
    "\n",
    "\n",
    "env = ParallelEnvBatch(make_env, nenvs=16)\n",
    "\n",
    "print(env.observation_space.shape)\n",
    "print(env.action_space.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "north-virus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 3)\n"
     ]
    }
   ],
   "source": [
    "curr = env.reset()\n",
    "print(curr.shape)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "obs = np.array([curr for _ in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cardiovascular-destiny",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a Vector Env\n",
      "<class 'rlkits.env_batch.ParallelEnvBatch'>\n"
     ]
    }
   ],
   "source": [
    "from rlkits.policies import PolicyWithValue\n",
    "from rlkits.env_batch import ParallelEnvBatch\n",
    "import numpy as np\n",
    "import gym\n",
    "from rlkits.sampler import TrajectorySampler\n",
    "\n",
    "def make_env():\n",
    "    return gym.make('Pendulum-v0')\n",
    "\n",
    "env = ParallelEnvBatch(make_env, nenvs=16)\n",
    "\n",
    "#env = make_env()\n",
    "\n",
    "\n",
    "ob_space = env.observation_space\n",
    "ac_space = env.action_space\n",
    "\n",
    "pi = PolicyWithValue(\n",
    "    ob_space=ob_space, ac_space=ac_space, ckpt_dir='/tmp', \n",
    "    hidden_layers=[1024])\n",
    "\n",
    "\n",
    "samp = TrajectorySampler(env, pi, 5)\n",
    "#ac, log_prob, v = policy.step(curr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "intensive-chase",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not isinstance(env, ParallelEnvBatch):\n",
    "    print('false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "iraqi-spread",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = np.random.rand(16, 3)\n",
    "\n",
    "t = np.random.rand(16)\n",
    "done = (t > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "advanced-chess",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "done.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "trying-referral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.92563383, 0.55998717, 0.65613426],\n",
       "       [0.94821461, 0.88353904, 0.36528434],\n",
       "       [0.15110719, 0.7119068 , 0.7472019 ],\n",
       "       [0.75858051, 0.70755973, 0.4250092 ],\n",
       "       [0.69849213, 0.30402498, 0.11032107],\n",
       "       [0.14048728, 0.29181518, 0.38692375],\n",
       "       [0.79454275, 0.70728973, 0.29947912]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx[done]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-attention",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_state (2, 3)\n",
    "rew (2,)\n",
    "done (2,) bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "environmental-valley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.97061545, -0.24063592, -0.565105  ],\n",
       "       [-0.18096242,  0.98349001,  2.07499883]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nxstate = np.array([\n",
    "    [ 0.97061545, -0.24063592, -0.565105],\n",
    " [-0.18096242,0.98349001,2.07499883]])\n",
    "done = np.array([False,False])\n",
    "\n",
    "nxstate[~done]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "accurate-archive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.76228153, 0.38908259, 0.09040862],\n",
       "       [0.76929873, 0.14689109, 0.05569494]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx_state = np.random.rand(2, 3)\n",
    "done = np.array([False, False])\n",
    "\n",
    "nx_state[~done]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patient-cooperative",
   "metadata": {},
   "source": [
    "# how to compute average episode rewards for a parallel env?\n",
    "```\n",
    "curr_ep_ret = [e1, e2, ..., en]\n",
    "\n",
    "if env 2 is done\n",
    "ep_ret[2].append(curr_ep_ret[2])\n",
    "curr_ep_ret[2] = 0\n",
    "\n",
    "```\n",
    "so I get a list of list for `ep_rets` such that `ep_rets[i]` is the return from env i\n",
    "\n",
    "Same idea can be applied to episodic length. Create a list of list for the \n",
    "`ep_lens` variable\n",
    "such that `ep_lens[i]` is the length of episode for env i. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_p36",
   "language": "python",
   "name": "pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
